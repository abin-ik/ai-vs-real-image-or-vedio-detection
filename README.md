# ğŸ§  AI vs Real Image Detection (Vision Transformer)

A deep learning project that fine-tunes a **Vision Transformer (ViT)** model to classify images as **REAL** or **AI-GENERATED (FAKE)**. This project uses **PyTorch** and **Hugging Face Transformers**, and is designed to be **interview-ready, modular, and production-friendly**.

---

## ğŸš€ Project Overview

With the rapid growth of generative AI, distinguishing real images from AI-generated ones has become critical. This project addresses that problem by:

* Leveraging a **pretrained Vision Transformer (ViT)** model
* Freezing the ViT backbone to retain learned visual features
* Fine-tuning only the classification head for binary classification
* Using Hugging Face's **Trainer API** for clean and scalable training

---

## ğŸ§© Model Architecture

* **Backbone:** Vision Transformer (ViT)
* **Input Size:** 224 Ã— 224 RGB images
* **Output Classes:**

  * `0 â†’ REAL`
  * `1 â†’ FAKE`

### ğŸ”’ Transfer Learning Strategy

* All ViT backbone layers are **frozen**
* Only the **classification head** is trained
* This reduces overfitting and speeds up training

---

## ğŸ“‚ Dataset Structure

The dataset must follow this folder structure:

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ REAL/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ img2.jpg
â”‚   â””â”€â”€ FAKE/
â”‚       â”œâ”€â”€ img1.jpg
â”‚       â””â”€â”€ img2.jpg
â”‚
â””â”€â”€ test/
    â”œâ”€â”€ REAL/
    â””â”€â”€ FAKE/
```

---

## ğŸ› ï¸ Tech Stack

* **Python 3.9+**
* **PyTorch**
* **Hugging Face Transformers**
* **Scikit-learn**
* **Pillow (PIL)**

---

## âš™ï¸ Installation

```bash
pip install torch transformers scikit-learn pillow
```

(Optional, for GPU support)

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ§ª Training Configuration

| Parameter     | Value           |
| ------------- | --------------- |
| Batch Size    | 16              |
| Epochs        | 2               |
| Learning Rate | 1e-4            |
| Evaluation    | Every 500 steps |
| Metric        | Accuracy        |

---

## ğŸ“Š Evaluation Metric

The model is evaluated using **classification accuracy**:

```python
accuracy = correct_predictions / total_predictions
```

---

## ğŸ‹ï¸ Training

To start fine-tuning the model:

```bash
python train.py
```

The best-performing model checkpoint is automatically saved.

---

## ğŸ“Œ Key Features

âœ… Vision Transformerâ€“based classification
âœ… Transfer learning with frozen backbone
âœ… Clean custom PyTorch Dataset
âœ… Hugging Face Trainer integration
âœ… Modular and extensible design

---

## ğŸ§  Possible Improvements

* Gradual layer unfreezing
* Class imbalance handling
* Precision / Recall / F1-score metrics
* Integration with Streamlit or FastAPI
* RAG-based explainability layer

---

## ğŸ‘¨â€ğŸ’» Author

**Abin**
Full-Stack AI Engineer | ML | DL | NLP | Vision

---

## ğŸ“œ License

This project is intended for **educational and research purposes**.

---

â­ If you like this project, give it a star and feel free to contribute!
